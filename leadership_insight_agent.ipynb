{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pymupdf\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import base64\n",
    "import io\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from config import Config\n",
    "\n",
    "\n",
    "# Input documents folder\n",
    "DATA_FOLDER = Config.DATA_FOLDER\n",
    "\n",
    "# API Keys\n",
    "GROQ_API_KEY = Config.GROQ_API_KEY \n",
    "OPENAI_API_KEY = Config.OPENAI_API_KEY\n",
    "\n",
    "LLM_MODEL = Config.LLM_MODEL \n",
    "\n",
    "# Document Processing\n",
    "CHUNK_SIZE = Config.CHUNK_SIZE\n",
    "CHUNK_OVERLAP = Config.CHUNK_OVERLAP\n",
    "\n",
    "CLIP_MODEL = Config.CLIP_MODEL\n",
    "TEXT_EMBEDDING = Config.TEXT_EMBEDDING\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 512)\n",
       "      (position_embedding): Embedding(77, 512)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (vision_model): CLIPVisionTransformer(\n",
       "    (embeddings): CLIPVisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "      (position_embedding): Embedding(50, 768)\n",
       "    )\n",
       "    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Initialise LLM\n",
    "# llm = ChatGroq(\n",
    "#     model_name=\"openai/gpt-oss-120b\",\n",
    "#     temperature=0.7\n",
    "# )\n",
    "\n",
    "llm =  init_chat_model(\n",
    "    model=LLM_MODEL,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "\n",
    "### initialize the Clip Model for unified embeddings\n",
    "clip_model=CLIPModel.from_pretrained(CLIP_MODEL)\n",
    "clip_processor=CLIPProcessor.from_pretrained(CLIP_MODEL)\n",
    "clip_model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Embedding functions\n",
    "def embed_image(image_data):\n",
    "    \"\"\"Embed image using CLIP\"\"\"\n",
    "    if isinstance(image_data, str):  # If path\n",
    "        image = Image.open(image_data).convert(\"RGB\")\n",
    "    else:  # If PIL Image\n",
    "        image = image_data\n",
    "    \n",
    "    inputs=clip_processor(images=image,return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        features = clip_model.get_image_features(**inputs)\n",
    "        # Normalize embeddings to unit vector\n",
    "        features = features / features.norm(dim=-1, keepdim=True)\n",
    "        return features.squeeze().numpy()\n",
    "    \n",
    "def embed_text(text):\n",
    "    \"\"\"Embed text using CLIP.\"\"\"\n",
    "    inputs = clip_processor(\n",
    "        text=text, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=77  # CLIP's max token length\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        features = clip_model.get_text_features(**inputs)\n",
    "        # Normalize embeddings\n",
    "        features = features / features.norm(dim=-1, keepdim=True)\n",
    "        return features.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data\"\n",
    "\n",
    "## Process PDF\n",
    "\n",
    "# Storage for all documents and embeddings\n",
    "all_docs = []\n",
    "all_embeddings = []\n",
    "image_data_store = {}  # Store actual image data for LLM\n",
    "documents = []\n",
    "\n",
    "# Text splitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=150)\n",
    "\n",
    "\n",
    "for filename in os.listdir(DATA_FOLDER):\n",
    "\n",
    "    if filename.endswith(\".pdf\"):\n",
    "\n",
    "        pdf_path = os.path.join(DATA_FOLDER, filename)\n",
    "\n",
    "        pdf = pymupdf.open(pdf_path)\n",
    "\n",
    "        for i,page in enumerate(pdf):\n",
    "\n",
    "            text = pdf[i].get_text()\n",
    "            if text.strip():\n",
    "                ##create temporary document for splitting\n",
    "                temp_doc = Document(page_content=text, metadata={\n",
    "                        \"source\": filename,\n",
    "                        \"page\": i + 1,\n",
    "                        \"type\": \"text\"\n",
    "                    })\n",
    "                text_chunks = splitter.split_documents([temp_doc])\n",
    "\n",
    "                #Embed each chunk using CLIP\n",
    "                for chunk in text_chunks:\n",
    "                    embedding = embed_text(chunk.page_content)\n",
    "                    all_embeddings.append(embedding)\n",
    "                    all_docs.append(chunk)\n",
    "        \n",
    "            # Extract images\n",
    "            image_list = page.get_images(full=True)\n",
    "            for img_index, img in enumerate(image_list):\n",
    "                try:\n",
    "                    xref = img[0]\n",
    "                    base_image = pdf.extract_image(xref)\n",
    "                    image_bytes = base_image[\"image\"]\n",
    "                    image_ext = base_image[\"ext\"]\n",
    "                    \n",
    "                    # Create PIL Image from bytes\n",
    "                    image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "                    \n",
    "                    # Embed the image\n",
    "                    image_embedding = embed_image(image)\n",
    "                    \n",
    "                    # Store the embedding and metadata\n",
    "                    all_embeddings.append(image_embedding)\n",
    "                    doc_metadata = {\n",
    "                        \"source\": filename,\n",
    "                        \"page\": i + 1,\n",
    "                        \"type\": \"image\",\n",
    "                        \"image_index\": img_index + 1\n",
    "                    }\n",
    "                    all_docs.append(Document(page_content=\"\", metadata=doc_metadata))\n",
    "                    \n",
    "                    # Store actual image data for later retrieval\n",
    "                    image_data_store[(filename, i + 1, img_index + 1)] = image\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {img_index + 1} on page {i + 1} of {filename}: {e}\")\n",
    "        \n",
    "        pdf.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.06409239e-02,  6.15886040e-03,  3.80151998e-03, ...,\n",
       "         4.01898697e-02, -2.52230950e-02,  5.00337966e-02],\n",
       "       [ 2.34374683e-02, -1.09239388e-02, -2.35859491e-02, ...,\n",
       "         8.61070305e-02,  2.78107147e-03, -1.11164972e-02],\n",
       "       [ 2.62417123e-02, -1.36267962e-02, -3.89178516e-03, ...,\n",
       "         6.22377880e-02, -4.83990880e-03, -7.18384981e-03],\n",
       "       ...,\n",
       "       [ 9.66303237e-03, -1.42385792e-02, -4.28498499e-02, ...,\n",
       "        -1.60443522e-02, -4.77830553e-03, -6.92308182e-03],\n",
       "       [ 2.86734793e-02, -1.84583501e-03, -1.77934859e-02, ...,\n",
       "        -6.97790086e-02, -1.12668646e-03,  3.58959921e-02],\n",
       "       [-4.70399391e-03, -3.68150868e-05, -1.22455275e-02, ...,\n",
       "         1.53705652e-03, -1.91832520e-02, -3.49148400e-02]],\n",
       "      shape=(1877, 512), dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create unified FAISS vector store with CLIP embeddings\n",
    "embeddings_array = np.array(all_embeddings)\n",
    "embeddings_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1877, 1877)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_docs), len(embeddings_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x128281e80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create custom FAISS index since we have precomputed embeddings\n",
    "vector_store = FAISS.from_embeddings(\n",
    "    text_embeddings=[(doc.page_content, emb) for doc, emb in zip(all_docs, embeddings_array)],\n",
    "    embedding=None,  # We're using precomputed embeddings\n",
    "    metadatas=[doc.metadata for doc in all_docs]\n",
    ")\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_multimodal(query, k=5):\n",
    "    \"\"\"Unified retrieval using CLIP embeddings for both text and images.\"\"\"\n",
    "    # Embed query using CLIP\n",
    "    query_embedding = embed_text(query)\n",
    "    \n",
    "    # Search in unified vector store\n",
    "    results = vector_store.similarity_search_by_vector(\n",
    "        embedding=query_embedding,\n",
    "        k=k\n",
    "    )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_cache = {}\n",
    "\n",
    "def describe_image(image_id):\n",
    "\n",
    "    if image_id in vision_cache:\n",
    "        return vision_cache[image_id]\n",
    "\n",
    "    image = image_data_store[image_id]\n",
    "\n",
    "    buffered = io.BytesIO()\n",
    "\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "\n",
    "    base64_image = base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "    response = llm.invoke([{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Describe this chart or image\"},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }])\n",
    "\n",
    "    vision_cache[image_id] = response.content\n",
    "\n",
    "    return response.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multimodal_message(query, retrieved_docs):\n",
    "    \"\"\"Create a message with both text and images for GPT-4V.\"\"\"\n",
    "    content = []\n",
    "    \n",
    "    # Add the query\n",
    "    content.append({\n",
    "        \"type\": \"text\",\n",
    "        \"text\": f\"Question: {query}\\n\\nContext:\\n\"\n",
    "    })\n",
    "    \n",
    "    # Separate text and image documents\n",
    "    text_docs = [doc for doc in retrieved_docs if doc.metadata.get(\"type\") == \"text\"]\n",
    "    image_docs = [doc for doc in retrieved_docs if doc.metadata.get(\"type\") == \"image\"]\n",
    "    \n",
    "    # Add text context\n",
    "    if text_docs:\n",
    "        text_context = \"\\n\\n\".join([\n",
    "            f\"[Page {doc.metadata['page']}]: {doc.page_content}\"\n",
    "            for doc in text_docs\n",
    "        ])\n",
    "        content.append({\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"Text excerpts:\\n{text_context}\\n\"\n",
    "        })\n",
    "    \n",
    "    # Add images\n",
    "    for doc in image_docs:\n",
    "        image_id = doc.metadata.get(\"image_id\")\n",
    "        if image_id and image_id in image_data_store:\n",
    "            content.append({\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"\\n[Image from page {doc.metadata['page']}]:\\n\"\n",
    "            })\n",
    "            content.append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/png;base64,{image_data_store[image_id]}\"\n",
    "                }\n",
    "            })\n",
    "            content.append({\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f\"\\nImage Description: {describe_image(image_id)}\\n\"\n",
    "            })\n",
    "    \n",
    "    return HumanMessage(content=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG AGENT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class RAGReflectionState(BaseModel):\n",
    "    # Required field\n",
    "    question: str\n",
    "    \n",
    "    # Fields with explicit defaults (making them truly optional for .invoke)\n",
    "    retrieved_docs: List[Document] = Field(default_factory=list) \n",
    "    rerank_retrieved_docs: List[Document] = Field(default_factory=list)\n",
    "    answer: Optional[str] = None\n",
    "    reflection: Optional[str] = None\n",
    "    revised: bool = False\n",
    "    attempts: int = 0\n",
    "    is_allowed: bool = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "import json\n",
    "\n",
    "\n",
    "# --- NODE 1: RETRIEVER ---\n",
    "def retriever_node(state: RAGReflectionState) -> RAGReflectionState:\n",
    "    query = state.question \n",
    "    # Using your unified CLIP retrieval function\n",
    "    docs = retrieve_multimodal(query, k=7)\n",
    "    return {\"retrieved_docs\": docs}\n",
    "\n",
    "\n",
    "## NODE 2 : ReRANKER\n",
    "def rerank_documents_node(state: RAGReflectionState):\n",
    "    query = state.question\n",
    "    docs = state.retrieved_docs\n",
    "    \n",
    "    if not docs:\n",
    "        return {\"retrieved_docs\": [], \"rerank_retrieved_docs\": []}\n",
    "\n",
    "    # Format documents for the LLM\n",
    "    doc_texts = \"\\n\".join([\n",
    "        f\"ID: {i}\\nContent: {doc.page_content[:500]}\" \n",
    "        for i, doc in enumerate(docs)\n",
    "    ])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert search ranker. Given the user query and a list of documents, \n",
    "    determine which documents are most relevant to answer the question.\n",
    "    \n",
    "    Query: {query}\n",
    "    \n",
    "    Documents:\n",
    "    {doc_texts}\n",
    "    \n",
    "    Return only a JSON list of IDs in order of relevance, for example: [2, 0, 3].\n",
    "    Only include IDs of documents that are truly relevant.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get ranking from LLM\n",
    "    response = llm.invoke(prompt)\n",
    "    try:\n",
    "        # Extract ID list from response\n",
    "        # Using a simple strip in case LLM adds markdown backticks\n",
    "        raw_content = response.content.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        relevant_ids = json.loads(raw_content)\n",
    "        \n",
    "        # Reorder and filter original docs based on LLM decision\n",
    "        rerank_retrieved_docs = [docs[idx] for idx in relevant_ids if idx < len(docs)]\n",
    "    except Exception as e:\n",
    "        print(f\"Reranking failed, falling back to original docs: {e}\")\n",
    "        rerank_retrieved_docs = docs[:3] # Fallback to top 3\n",
    "\n",
    "    return {\"rerank_retrieved_docs\": rerank_retrieved_docs}\n",
    "\n",
    "\n",
    "\n",
    "# --- NODE 3: ANSWER GENERATOR ---\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "def generate_answer_node(state: RAGReflectionState):\n",
    "    # 1. Get the list of blocks [{type: text, ...}, {type: image_url, ...}]\n",
    "    multimodal_content = create_multimodal_message(state.question, state.rerank_retrieved_docs)\n",
    "    \n",
    "    # print(\"Multimodal content for LLM:\", multimodal_content)\n",
    "\n",
    "    # 2. Check: if multimodal_content is accidentally a Message object, extract content\n",
    "    if hasattr(multimodal_content, 'content'):\n",
    "        multimodal_content = multimodal_content.content\n",
    "\n",
    "    # 3. Create the messages list using raw dictionaries for the user part\n",
    "    # This bypasses the HumanMessage Pydantic validation error\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are Adobe AI Leadership Insight and Decision Agent, who understand the financial reports and data of Adobe. Answer question using provided context. Answer should be concise and to the point.\"},\n",
    "        {\"role\": \"user\", \"content\": multimodal_content} \n",
    "    ]\n",
    "    \n",
    "    # print(messages)\n",
    "    # 4. Invoke with the clean list\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return {\n",
    "        \"answer\": response.content.strip(),\n",
    "        \"attempts\": state.attempts + 1\n",
    "    }\n",
    "\n",
    "\n",
    "# --- NODE 4: REFLECTOR ---\n",
    "def reflection_node(state: RAGReflectionState)  -> RAGReflectionState:\n",
    "    prompt = f\"\"\"\n",
    "    Reflect on the following answer and context. State \"YES\" if satisfactory or \"NO\" if not.\n",
    "    Question: {state.question}\n",
    "    Answer: {state.answer}\n",
    "    Context: {state.rerank_retrieved_docs}\n",
    "    Respond like:\n",
    "    Reflection: YES or NO. \n",
    "    Reflection score: 0-10 (10 being perfect)\n",
    "    Explanation: ...\n",
    "    \"\"\"\n",
    "    \n",
    "    reflection = llm.invoke(prompt).content\n",
    "    is_ok = \"reflection: yes\" in reflection.lower()\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        \"reflection\": reflection, \n",
    "        \"revised\": not is_ok\n",
    "    }\n",
    "\n",
    "# --- NODE 5: FINALIZER ---\n",
    "# def finalize_node(state: RAGReflectionState)    -> RAGReflectionState:\n",
    "#     # This node just acts as a cleanup/formatting step before END\n",
    "#     return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In your finalize_node, handle the blocked message\n",
    "def finalize_node(state: RAGReflectionState):\n",
    "    if not state.is_allowed:\n",
    "        return {\"answer\": \"I am an Adobe-specific assistant. I can only answer questions related to Adobe's reports and products.\"}\n",
    "    # ... (rest of your finalize logic)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardrail_node(state: RAGReflectionState):\n",
    "    prompt = f\"\"\"\n",
    "    You are a security gatekeeper for an Adobe Financial RAG agent. \n",
    "    Your task is to determine if the following question is related to Adobe (its finances, products like Photoshop/Firefly, strategy, or reports).\n",
    "\n",
    "    Question: {state.question}\n",
    "\n",
    "    If the question is about Adobe, respond exactly with \"ALLOWED\".\n",
    "    If it is NOT about Adobe (e.g., asking about cooking, other companies like Apple, or general trivia), respond with \"BLOCKED\".\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt).content.strip().upper()\n",
    "    is_allowed = \"ALLOWED\" in response\n",
    "    \n",
    "    return {\"is_allowed\": is_allowed}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building graph workflow \n",
    "\n",
    "\n",
    "# Conditional Logic: Loop back to retriever if \"revised\" is True and attempts < 2\n",
    "def route_after_reflection(state: RAGReflectionState):\n",
    "    if not state.revised or state.attempts >= 2:\n",
    "        return \"complete\"\n",
    "    else:\n",
    "        return \"retry\"\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Rebuild with Reranking Node \n",
    "\n",
    "builder = StateGraph(RAGReflectionState)\n",
    "\n",
    "\n",
    "\n",
    "# Add Nodes\n",
    "builder.add_node(\"guardrail\", guardrail_node)\n",
    "builder.add_node(\"retriever\", retriever_node)\n",
    "builder.add_node(\"reranker\", rerank_documents_node) \n",
    "builder.add_node(\"answer_generator\", generate_answer_node)\n",
    "builder.add_node(\"reflector\", reflection_node)\n",
    "builder.add_node(\"done\", finalize_node)\n",
    "\n",
    "# # Update Flow (Edges)\n",
    "# builder.set_entry_point(\"retriever\")\n",
    "\n",
    "\n",
    "\n",
    "# Define the gatekeeping flow\n",
    "builder.set_entry_point(\"guardrail\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"guardrail\",\n",
    "    lambda s: \"continue\" if s.is_allowed else \"stop\",\n",
    "    {\n",
    "        \"continue\": \"retriever\",\n",
    "        \"stop\": \"done\" # Skip directly to finalize\n",
    "    }\n",
    ")\n",
    "builder.add_edge(\"retriever\", \"reranker\")        \n",
    "builder.add_edge(\"reranker\", \"answer_generator\")\n",
    "builder.add_edge(\"answer_generator\", \"reflector\")\n",
    "\n",
    "# Update Conditional Logic\n",
    "builder.add_conditional_edges(\n",
    "    \"reflector\",\n",
    "    route_after_reflection,\n",
    "    {\n",
    "        \"complete\": \"done\",\n",
    "        \"retry\": \"retriever\" # Retry starts back at retrieval\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"done\", END)\n",
    "adobe_rag_app_with_reranker = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1=\"What is Adobe's revenue in 2024 and how does it compare to 2022?\"\n",
    "question2=\"What was Adobe's total revenue for Fiscal Year 2024?\"\n",
    "question3=\"Based on the 'Digital Media ARR' chart, what was the ending ARR for 2024?\"\n",
    "question4=\"How is Adobe integrating generative AI across its Creative Cloud suite?\"\n",
    "question5=\"Based on the R&D spend and product roadmap, which product is Adobe prioritizing for 2025?.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION--   What is Adobe's revenue in 2024 and how does it compare to 2022?\n",
      "--- FINAL ANSWER ---\n",
      "\n",
      "Adobe's total revenue in 2024 is $21,505 million. Compared to 2022, when the total revenue was $17,606 million, Adobe's revenue in 2024 increased by $3,899 million.\n",
      "\n",
      "--- ATTEMPTS: 1 ---\n",
      "\n",
      "--- CONTEXT DOC: [Document(id='60579121-f7f2-4bb2-b879-165ab36a8c2c', metadata={'source': 'adbe-Q4 and FY24 Earnings.pdf', 'page': 2, 'type': 'text'}, page_content='The following table summarizes Adobe’s fiscal year 2025 targets1: \\n \\nTotal revenue \\n$23.30 billion to $23.55 billion \\nDigital Media segment revenue \\n$17.25 billion to $17.40 billion \\nDigital Media ending ARR growth \\n11.0% year over year \\nDigital Experience segment revenue \\n$5.80 billion to $5.90 billion \\nDigital Experience subscription revenue \\n$5.375 billion to $5.425 billion \\nEarnings per share \\nGAAP: $15.80 to $16.10 \\nNon-GAAP: $20.20 to $20.50 \\n1 Targets assume non-GAAP operating margin of ~46 percent, non-GAAP tax rate of ~18.5 percent and diluted share count of ~433 \\nmillion for fiscal year 2025. \\nThe following table summarizes Adobe’s first quarter fiscal year 2025 targets2: \\n \\nTotal revenue \\n$5.63 billion to $5.68 billion \\nDigital Media segment revenue'), Document(id='fd93a746-ca44-4e8b-8af2-4fb13771aa98', metadata={'source': 'Adobe Reports Record Q4 and FY2025 Revenue.pdf', 'page': 2, 'type': 'text'}, page_content='The following table summarizes Adobe’s first quarter FY2026 targets2:\\nTotal revenue\\n$6.25 billion to $6.30 billion\\nBusiness Professionals & Consumers subscription revenue\\n$1.74 billion to $1.76 billion\\nCreative & Marketing Professionals subscription revenue\\n$4.30 billion to $4.33 billion\\nEarnings per share\\nGAAP: $4.55 to $4.60\\nNon-GAAP: $5.85 to $5.90\\n2 Targets assume non-GAAP operating margin of ~47.0%, GAAP tax rate of ~21.5%, non-GAAP tax rate of ~18.0% and diluted \\nshare count of ~411 million for first quarter FY2026.\\n2'), Document(id='ced692c5-67c9-4b68-8636-6a252d6e5e2f', metadata={'source': 'Adobe Reports Record Q4 and FY2025 Revenue.pdf', 'page': 2, 'type': 'text'}, page_content='• Adobe repurchased approximately 30.8 million shares during the year.\\nFY2025 Business Segment Highlights\\n• Digital Media segment revenue was $17.65 billion, which represents 11% year-over-year growth as reported and in constant currency. Digital \\nMedia ARR exiting the year was $19.20 billion, representing 11.5% year-over-year growth. \\n• Digital Experience segment revenue was $5.86 billion, representing 9% year-over-year growth as reported and in constant currency. Digital \\nExperience subscription revenue was $5.41 billion, representing 11% year-over-year growth as reported and in constant currency.\\nFY2025 Customer Group Highlights\\n• Total Customer Group subscription revenue was $22.80 billion, which represents 12% year-over-year growth as reported and in constant \\ncurrency.'), Document(id='b725393b-0de6-4f00-ac2a-563724948f5a', metadata={'source': 'adbe-2024-annual-report.pdf', 'page': 55, 'type': 'text'}, page_content='ADOBE INC.\\nCONSOLIDATED STATEMENTS OF INCOME\\n(In millions, except per share data)\\n \\nYears Ended\\n \\nNovember 29,\\n2024\\nDecember 1,\\n2023\\nDecember 2,\\n2022\\nRevenue:\\n \\nSubscription     ...................................................................................................... $ \\n20,521 $ \\n18,284 $ \\n16,388 \\nProduct    .............................................................................................................  \\n386  \\n460  \\n532 \\nServices and other      ............................................................................................  \\n598  \\n665  \\n686 \\nTotal revenue     ...............................................................................................  \\n21,505  \\n19,409  \\n17,606 \\n \\nCost of revenue:'), Document(id='aaa499d6-8a69-48b2-b128-81b5e4850074', metadata={'source': 'adbe-2025-proxy-statemnt.pdf', 'page': 59, 'type': 'text'}, page_content='appropriate expenses for the benefit of Adobe and its stockholders. Since the costs arise from the nature of our CEO’s role and \\nExecutive Compensation  |  2025 Proxy Statement       49')] ---\n",
      "\n",
      "--- Reranked CONTEXT DOC: [Document(id='b725393b-0de6-4f00-ac2a-563724948f5a', metadata={'source': 'adbe-2024-annual-report.pdf', 'page': 55, 'type': 'text'}, page_content='ADOBE INC.\\nCONSOLIDATED STATEMENTS OF INCOME\\n(In millions, except per share data)\\n \\nYears Ended\\n \\nNovember 29,\\n2024\\nDecember 1,\\n2023\\nDecember 2,\\n2022\\nRevenue:\\n \\nSubscription     ...................................................................................................... $ \\n20,521 $ \\n18,284 $ \\n16,388 \\nProduct    .............................................................................................................  \\n386  \\n460  \\n532 \\nServices and other      ............................................................................................  \\n598  \\n665  \\n686 \\nTotal revenue     ...............................................................................................  \\n21,505  \\n19,409  \\n17,606 \\n \\nCost of revenue:')] ---\n",
      "\n",
      "--- Reflection: Reflection: YES  \n",
      "Reflection score: 10  \n",
      "Explanation: The answer accurately reflects the information provided in the context. It correctly states Adobe's total revenue for 2024 as $21,505 million and compares it to the 2022 revenue of $17,606 million, noting an increase of $3,899 million. The figures and comparison are consistent with the data from the provided document. ---\n"
     ]
    }
   ],
   "source": [
    "initial_state = RAGReflectionState(\n",
    "        question=question1\n",
    "    )\n",
    "final_state = adobe_rag_app_with_reranker.invoke(initial_state)\n",
    "\n",
    "print(\"QUESTION--  \",initial_state.question)\n",
    "\n",
    "print(f\"--- FINAL ANSWER ---\\n\\n{final_state['answer']}\\n\")\n",
    "print(f\"--- ATTEMPTS: {final_state['attempts']} ---\\n\")\n",
    "print(f\"--- CONTEXT DOC: {final_state['retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reranked CONTEXT DOC: {final_state['rerank_retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reflection: {final_state['reflection']} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION--   What is Adobe's revenue in 2024 and how does it compare to 2022?\n",
      "--- FINAL ANSWER ---\n",
      "\n",
      "Adobe's revenue in 2024 is $21,505 million. Compared to 2022, where the revenue was $17,606 million, there is an increase of $3,899 million.\n",
      "\n",
      "--- ATTEMPTS: 1 ---\n",
      "\n",
      "--- CONTEXT DOC: [Document(id='60579121-f7f2-4bb2-b879-165ab36a8c2c', metadata={'source': 'adbe-Q4 and FY24 Earnings.pdf', 'page': 2, 'type': 'text'}, page_content='The following table summarizes Adobe’s fiscal year 2025 targets1: \\n \\nTotal revenue \\n$23.30 billion to $23.55 billion \\nDigital Media segment revenue \\n$17.25 billion to $17.40 billion \\nDigital Media ending ARR growth \\n11.0% year over year \\nDigital Experience segment revenue \\n$5.80 billion to $5.90 billion \\nDigital Experience subscription revenue \\n$5.375 billion to $5.425 billion \\nEarnings per share \\nGAAP: $15.80 to $16.10 \\nNon-GAAP: $20.20 to $20.50 \\n1 Targets assume non-GAAP operating margin of ~46 percent, non-GAAP tax rate of ~18.5 percent and diluted share count of ~433 \\nmillion for fiscal year 2025. \\nThe following table summarizes Adobe’s first quarter fiscal year 2025 targets2: \\n \\nTotal revenue \\n$5.63 billion to $5.68 billion \\nDigital Media segment revenue'), Document(id='fd93a746-ca44-4e8b-8af2-4fb13771aa98', metadata={'source': 'Adobe Reports Record Q4 and FY2025 Revenue.pdf', 'page': 2, 'type': 'text'}, page_content='The following table summarizes Adobe’s first quarter FY2026 targets2:\\nTotal revenue\\n$6.25 billion to $6.30 billion\\nBusiness Professionals & Consumers subscription revenue\\n$1.74 billion to $1.76 billion\\nCreative & Marketing Professionals subscription revenue\\n$4.30 billion to $4.33 billion\\nEarnings per share\\nGAAP: $4.55 to $4.60\\nNon-GAAP: $5.85 to $5.90\\n2 Targets assume non-GAAP operating margin of ~47.0%, GAAP tax rate of ~21.5%, non-GAAP tax rate of ~18.0% and diluted \\nshare count of ~411 million for first quarter FY2026.\\n2'), Document(id='ced692c5-67c9-4b68-8636-6a252d6e5e2f', metadata={'source': 'Adobe Reports Record Q4 and FY2025 Revenue.pdf', 'page': 2, 'type': 'text'}, page_content='• Adobe repurchased approximately 30.8 million shares during the year.\\nFY2025 Business Segment Highlights\\n• Digital Media segment revenue was $17.65 billion, which represents 11% year-over-year growth as reported and in constant currency. Digital \\nMedia ARR exiting the year was $19.20 billion, representing 11.5% year-over-year growth. \\n• Digital Experience segment revenue was $5.86 billion, representing 9% year-over-year growth as reported and in constant currency. Digital \\nExperience subscription revenue was $5.41 billion, representing 11% year-over-year growth as reported and in constant currency.\\nFY2025 Customer Group Highlights\\n• Total Customer Group subscription revenue was $22.80 billion, which represents 12% year-over-year growth as reported and in constant \\ncurrency.'), Document(id='b725393b-0de6-4f00-ac2a-563724948f5a', metadata={'source': 'adbe-2024-annual-report.pdf', 'page': 55, 'type': 'text'}, page_content='ADOBE INC.\\nCONSOLIDATED STATEMENTS OF INCOME\\n(In millions, except per share data)\\n \\nYears Ended\\n \\nNovember 29,\\n2024\\nDecember 1,\\n2023\\nDecember 2,\\n2022\\nRevenue:\\n \\nSubscription     ...................................................................................................... $ \\n20,521 $ \\n18,284 $ \\n16,388 \\nProduct    .............................................................................................................  \\n386  \\n460  \\n532 \\nServices and other      ............................................................................................  \\n598  \\n665  \\n686 \\nTotal revenue     ...............................................................................................  \\n21,505  \\n19,409  \\n17,606 \\n \\nCost of revenue:'), Document(id='aaa499d6-8a69-48b2-b128-81b5e4850074', metadata={'source': 'adbe-2025-proxy-statemnt.pdf', 'page': 59, 'type': 'text'}, page_content='appropriate expenses for the benefit of Adobe and its stockholders. Since the costs arise from the nature of our CEO’s role and \\nExecutive Compensation  |  2025 Proxy Statement       49')] ---\n",
      "\n",
      "--- Reranked CONTEXT DOC: [Document(id='b725393b-0de6-4f00-ac2a-563724948f5a', metadata={'source': 'adbe-2024-annual-report.pdf', 'page': 55, 'type': 'text'}, page_content='ADOBE INC.\\nCONSOLIDATED STATEMENTS OF INCOME\\n(In millions, except per share data)\\n \\nYears Ended\\n \\nNovember 29,\\n2024\\nDecember 1,\\n2023\\nDecember 2,\\n2022\\nRevenue:\\n \\nSubscription     ...................................................................................................... $ \\n20,521 $ \\n18,284 $ \\n16,388 \\nProduct    .............................................................................................................  \\n386  \\n460  \\n532 \\nServices and other      ............................................................................................  \\n598  \\n665  \\n686 \\nTotal revenue     ...............................................................................................  \\n21,505  \\n19,409  \\n17,606 \\n \\nCost of revenue:')] ---\n",
      "\n",
      "--- Reflection: Reflection: YES  \n",
      "Reflection score: 10  \n",
      "Explanation: The answer accurately reflects the information provided in the context. It correctly states Adobe's revenue for 2024 as $21,505 million and compares it to the 2022 revenue of $17,606 million, noting an increase of $3,899 million. The figures and comparison are consistent with the data from the provided document. ---\n"
     ]
    }
   ],
   "source": [
    "initial_state = RAGReflectionState(\n",
    "        question=question1\n",
    "    )\n",
    "final_state = adobe_rag_app_with_reranker.invoke(initial_state)\n",
    "\n",
    "print(\"QUESTION--  \",initial_state.question)\n",
    "\n",
    "print(f\"--- FINAL ANSWER ---\\n\\n{final_state['answer']}\\n\")\n",
    "print(f\"--- ATTEMPTS: {final_state['attempts']} ---\\n\")\n",
    "print(f\"--- CONTEXT DOC: {final_state['retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reranked CONTEXT DOC: {final_state['rerank_retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reflection: {final_state['reflection']} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION--   What was Adobe's total revenue for Fiscal Year 2024?\n",
      "--- FINAL ANSWER ---\n",
      "\n",
      "Adobe's total revenue for Fiscal Year 2024 was $21,505 million.\n",
      "\n",
      "--- ATTEMPTS: 1 ---\n",
      "\n",
      "--- CONTEXT DOC: [Document(id='60579121-f7f2-4bb2-b879-165ab36a8c2c', metadata={'source': 'adbe-Q4 and FY24 Earnings.pdf', 'page': 2, 'type': 'text'}, page_content='The following table summarizes Adobe’s fiscal year 2025 targets1: \\n \\nTotal revenue \\n$23.30 billion to $23.55 billion \\nDigital Media segment revenue \\n$17.25 billion to $17.40 billion \\nDigital Media ending ARR growth \\n11.0% year over year \\nDigital Experience segment revenue \\n$5.80 billion to $5.90 billion \\nDigital Experience subscription revenue \\n$5.375 billion to $5.425 billion \\nEarnings per share \\nGAAP: $15.80 to $16.10 \\nNon-GAAP: $20.20 to $20.50 \\n1 Targets assume non-GAAP operating margin of ~46 percent, non-GAAP tax rate of ~18.5 percent and diluted share count of ~433 \\nmillion for fiscal year 2025. \\nThe following table summarizes Adobe’s first quarter fiscal year 2025 targets2: \\n \\nTotal revenue \\n$5.63 billion to $5.68 billion \\nDigital Media segment revenue'), Document(id='b725393b-0de6-4f00-ac2a-563724948f5a', metadata={'source': 'adbe-2024-annual-report.pdf', 'page': 55, 'type': 'text'}, page_content='ADOBE INC.\\nCONSOLIDATED STATEMENTS OF INCOME\\n(In millions, except per share data)\\n \\nYears Ended\\n \\nNovember 29,\\n2024\\nDecember 1,\\n2023\\nDecember 2,\\n2022\\nRevenue:\\n \\nSubscription     ...................................................................................................... $ \\n20,521 $ \\n18,284 $ \\n16,388 \\nProduct    .............................................................................................................  \\n386  \\n460  \\n532 \\nServices and other      ............................................................................................  \\n598  \\n665  \\n686 \\nTotal revenue     ...............................................................................................  \\n21,505  \\n19,409  \\n17,606 \\n \\nCost of revenue:'), Document(id='fd93a746-ca44-4e8b-8af2-4fb13771aa98', metadata={'source': 'Adobe Reports Record Q4 and FY2025 Revenue.pdf', 'page': 2, 'type': 'text'}, page_content='The following table summarizes Adobe’s first quarter FY2026 targets2:\\nTotal revenue\\n$6.25 billion to $6.30 billion\\nBusiness Professionals & Consumers subscription revenue\\n$1.74 billion to $1.76 billion\\nCreative & Marketing Professionals subscription revenue\\n$4.30 billion to $4.33 billion\\nEarnings per share\\nGAAP: $4.55 to $4.60\\nNon-GAAP: $5.85 to $5.90\\n2 Targets assume non-GAAP operating margin of ~47.0%, GAAP tax rate of ~21.5%, non-GAAP tax rate of ~18.0% and diluted \\nshare count of ~411 million for first quarter FY2026.\\n2'), Document(id='aaa499d6-8a69-48b2-b128-81b5e4850074', metadata={'source': 'adbe-2025-proxy-statemnt.pdf', 'page': 59, 'type': 'text'}, page_content='appropriate expenses for the benefit of Adobe and its stockholders. Since the costs arise from the nature of our CEO’s role and \\nExecutive Compensation  |  2025 Proxy Statement       49'), Document(id='ced692c5-67c9-4b68-8636-6a252d6e5e2f', metadata={'source': 'Adobe Reports Record Q4 and FY2025 Revenue.pdf', 'page': 2, 'type': 'text'}, page_content='• Adobe repurchased approximately 30.8 million shares during the year.\\nFY2025 Business Segment Highlights\\n• Digital Media segment revenue was $17.65 billion, which represents 11% year-over-year growth as reported and in constant currency. Digital \\nMedia ARR exiting the year was $19.20 billion, representing 11.5% year-over-year growth. \\n• Digital Experience segment revenue was $5.86 billion, representing 9% year-over-year growth as reported and in constant currency. Digital \\nExperience subscription revenue was $5.41 billion, representing 11% year-over-year growth as reported and in constant currency.\\nFY2025 Customer Group Highlights\\n• Total Customer Group subscription revenue was $22.80 billion, which represents 12% year-over-year growth as reported and in constant \\ncurrency.')] ---\n",
      "\n",
      "--- Reranked CONTEXT DOC: [Document(id='b725393b-0de6-4f00-ac2a-563724948f5a', metadata={'source': 'adbe-2024-annual-report.pdf', 'page': 55, 'type': 'text'}, page_content='ADOBE INC.\\nCONSOLIDATED STATEMENTS OF INCOME\\n(In millions, except per share data)\\n \\nYears Ended\\n \\nNovember 29,\\n2024\\nDecember 1,\\n2023\\nDecember 2,\\n2022\\nRevenue:\\n \\nSubscription     ...................................................................................................... $ \\n20,521 $ \\n18,284 $ \\n16,388 \\nProduct    .............................................................................................................  \\n386  \\n460  \\n532 \\nServices and other      ............................................................................................  \\n598  \\n665  \\n686 \\nTotal revenue     ...............................................................................................  \\n21,505  \\n19,409  \\n17,606 \\n \\nCost of revenue:')] ---\n",
      "\n",
      "--- Reflection: Reflection: YES  \n",
      "Reflection score: 10  \n",
      "Explanation: The answer provided is accurate and directly supported by the context given. The context from the document clearly states that Adobe's total revenue for Fiscal Year 2024 was $21,505 million, which matches the answer. The information is extracted from a reliable source, specifically Adobe's consolidated statements of income, ensuring the answer's credibility. ---\n"
     ]
    }
   ],
   "source": [
    "initial_state = RAGReflectionState(\n",
    "        question=question2\n",
    "    )\n",
    "final_state = adobe_rag_app_with_reranker.invoke(initial_state)\n",
    "\n",
    "print(\"QUESTION--  \",initial_state.question)\n",
    "\n",
    "print(f\"--- FINAL ANSWER ---\\n\\n{final_state['answer']}\\n\")\n",
    "print(f\"--- ATTEMPTS: {final_state['attempts']} ---\\n\")\n",
    "print(f\"--- CONTEXT DOC: {final_state['retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reranked CONTEXT DOC: {final_state['rerank_retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reflection: {final_state['reflection']} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION--   Based on the 'Digital Media ARR' chart, what was the ending ARR for 2024?\n",
      "--- FINAL ANSWER ---\n",
      "\n",
      "The ending ARR for Digital Media in 2024 was between $21.30 billion and $21.50 billion.\n",
      "\n",
      "--- ATTEMPTS: 1 ---\n",
      "\n",
      "--- CONTEXT DOC: [Document(id='57289b00-74ab-457b-ac4e-46d48710f4fc', metadata={'source': 'adbe-investor-update-2024.pdf', 'page': 4, 'type': 'text'}, page_content='$21.30B to $21.50B\\n$21.40B to $21.50B\\nDigital Media net new ARR\\n~$1.90B\\n~$1.95B\\nDigital Media segment revenue\\n$15.75B to $15.85B\\n$15.80B to $15.85B\\nDigital Experience segment revenue\\n$5.275B to $5.375B\\n$5.325B to $5.375B\\nDigital Experience subscription revenue\\n$4.75B to $4.80B\\n$4.775B to $4.825B\\nGAAP diluted earnings per share\\n$13.45 to $13.85\\n$11.80 to $12.00\\nNon-GAAP diluted earnings per share\\n$17.60 to $18.00\\n$18.00 to $18.20\\nGAAP tax rate\\n~18.0%\\n~20.5%\\nNon-GAAP tax rate\\n~18.5%\\n~18.5%'), Document(id='e70e54d3-2b6c-4581-8e13-3fb1ebf7a092', metadata={'source': 'adbe-2024-annual-report.pdf', 'page': 43, 'type': 'text'}, page_content='2024-2023\\nDigital Media   .......................................................................................\\n$ 15,864 \\n$ 14,216 \\n$ 12,842 \\n 12 %\\nPercentage of total revenue   ...............................................................\\n 74 %\\n 73 %\\n 73 %  \\nDigital Experience     ...............................................................................\\n \\n5,366 \\n \\n4,893 \\n \\n4,422 \\n 10 %\\nPercentage of total revenue   ...............................................................\\n 25 %\\n 25 %\\n 25 %  \\nPublishing and Advertising      .................................................................\\n \\n275 \\n \\n300 \\n \\n342 \\n (8) %\\nPercentage of total revenue   ...............................................................\\n 1 %\\n 2 %\\n 2 %'), Document(id='e980b8eb-e06d-4afe-8c19-84d0e571dd5d', metadata={'source': 'adbe-2024-annual-report.pdf', 'page': 66, 'type': 'text'}, page_content='Our segment revenue and results for fiscal 2024, 2023 and 2022 were as follows:\\n(dollars in millions)\\nDigital \\nMedia\\nDigital \\nExperience\\nPublishing and \\nAdvertising\\nTotal\\nFiscal 2024\\nRevenue    ........................................................................................ $ \\n15,864 \\n$ \\n5,366 \\n$ \\n275 \\n$ \\n21,505 \\nCost of revenue  .............................................................................  \\n680 \\n \\n1,589 \\n \\n89 \\n \\n2,358 \\nGross profit  ................................................................................... $ \\n15,184 \\n$ \\n3,777 \\n$ \\n186 \\n$ \\n19,147 \\nGross profit as a percentage of revenue ........................................\\n 96 %\\n 70 %\\n 68 %\\n 89 %\\nFiscal 2023'), Document(id='f0041382-c6e7-459f-8479-c94cf4a95ffa', metadata={'source': 'adbe-2025-proxy-statemnt.pdf', 'page': 39, 'type': 'text'}, page_content='our non-employee directors was in compliance with these guidelines.\\nDirector Compensation  |  2025 Proxy Statement       29'), Document(id='96b4caf5-ba77-4cdd-b4b3-abc1b56d0c36', metadata={'source': 'adbe-2024-annual-report.pdf', 'page': 42, 'type': 'text'}, page_content='Revenue\\n(dollars in millions)\\n2024\\n2023\\n2022\\n% Change\\n2024-2023\\nSubscription  .........................................................................................\\n$ 20,521 \\n$ 18,284 \\n$ 16,388 \\n 12 %\\nPercentage of total revenue   ...............................................................\\n 95 %\\n 94 %\\n 93 %  \\nProduct    .................................................................................................\\n \\n386 \\n \\n460 \\n \\n532 \\n (16) %\\nPercentage of total revenue   ...............................................................\\n 2 %\\n 2 %\\n 3 %  \\nServices and other     ...............................................................................\\n \\n598 \\n \\n665 \\n \\n686 \\n (10) %\\nPercentage of total revenue   ...............................................................\\n 3 %')] ---\n",
      "\n",
      "--- Reranked CONTEXT DOC: [Document(id='57289b00-74ab-457b-ac4e-46d48710f4fc', metadata={'source': 'adbe-investor-update-2024.pdf', 'page': 4, 'type': 'text'}, page_content='$21.30B to $21.50B\\n$21.40B to $21.50B\\nDigital Media net new ARR\\n~$1.90B\\n~$1.95B\\nDigital Media segment revenue\\n$15.75B to $15.85B\\n$15.80B to $15.85B\\nDigital Experience segment revenue\\n$5.275B to $5.375B\\n$5.325B to $5.375B\\nDigital Experience subscription revenue\\n$4.75B to $4.80B\\n$4.775B to $4.825B\\nGAAP diluted earnings per share\\n$13.45 to $13.85\\n$11.80 to $12.00\\nNon-GAAP diluted earnings per share\\n$17.60 to $18.00\\n$18.00 to $18.20\\nGAAP tax rate\\n~18.0%\\n~20.5%\\nNon-GAAP tax rate\\n~18.5%\\n~18.5%'), Document(id='e980b8eb-e06d-4afe-8c19-84d0e571dd5d', metadata={'source': 'adbe-2024-annual-report.pdf', 'page': 66, 'type': 'text'}, page_content='Our segment revenue and results for fiscal 2024, 2023 and 2022 were as follows:\\n(dollars in millions)\\nDigital \\nMedia\\nDigital \\nExperience\\nPublishing and \\nAdvertising\\nTotal\\nFiscal 2024\\nRevenue    ........................................................................................ $ \\n15,864 \\n$ \\n5,366 \\n$ \\n275 \\n$ \\n21,505 \\nCost of revenue  .............................................................................  \\n680 \\n \\n1,589 \\n \\n89 \\n \\n2,358 \\nGross profit  ................................................................................... $ \\n15,184 \\n$ \\n3,777 \\n$ \\n186 \\n$ \\n19,147 \\nGross profit as a percentage of revenue ........................................\\n 96 %\\n 70 %\\n 68 %\\n 89 %\\nFiscal 2023')] ---\n",
      "\n",
      "--- Reflection: Reflection: YES.  \n",
      "Reflection score: 9.  \n",
      "Explanation: The answer provided is satisfactory as it correctly identifies the ending ARR for Digital Media in 2024 as being between $21.30 billion and $21.50 billion, which aligns with the information given in the context. The context provides a range for the Digital Media ARR, and the answer accurately reflects this range. The only reason for not giving a perfect score is that the answer could be more precise by stating the exact midpoint or the most likely figure if available, but given the range provided, the answer is still correct. ---\n"
     ]
    }
   ],
   "source": [
    "initial_state = RAGReflectionState(\n",
    "        question=question3\n",
    "    )\n",
    "final_state = adobe_rag_app_with_reranker.invoke(initial_state)\n",
    "\n",
    "print(\"QUESTION--  \",initial_state.question)\n",
    "\n",
    "print(f\"--- FINAL ANSWER ---\\n\\n{final_state['answer']}\\n\")\n",
    "print(f\"--- ATTEMPTS: {final_state['attempts']} ---\\n\")\n",
    "print(f\"--- CONTEXT DOC: {final_state['retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reranked CONTEXT DOC: {final_state['rerank_retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reflection: {final_state['reflection']} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION--   How is Adobe integrating generative AI across its Creative Cloud suite?\n",
      "--- FINAL ANSWER ---\n",
      "\n",
      "Adobe is integrating generative AI across its Creative Cloud suite by embedding AI capabilities into its applications to enhance creativity and productivity. This includes features like AI-driven content creation, automated design suggestions, and enhanced editing tools that leverage machine learning to assist users in generating and refining creative content more efficiently. These integrations aim to streamline workflows and provide users with innovative tools to expand their creative possibilities.\n",
      "\n",
      "--- ATTEMPTS: 1 ---\n",
      "\n",
      "--- CONTEXT DOC: [Document(id='0f439768-5fe4-4947-a522-99f75b85d1bd', metadata={'source': 'adbe-2024-annual-report.pdf', 'page': 5, 'type': 'text'}, page_content='our customers can easily generate and edit visuals directly in PDFs. We are unlocking business workflows through PDF and \\nAdobe Acrobat Sign Application Programming Interfaces (“APIs”); accelerating Document Cloud adoption through digital and \\n5'), Document(id='24641208-6175-4072-947b-58001d5722d8', metadata={'source': 'adbe-2025-proxy-statemnt.pdf', 'page': 4, 'type': 'text'}, page_content='governments around the world establish a federal anti-\\nimpersonation right enabling creators to take action against \\nthose who intentionally misuse AI tools to impersonate their \\nstyle.\\u202fWe continue to work toward reducing our impact on'), Document(id='bdf13ebc-7714-4a24-9e88-03b296faab4c', metadata={'source': 'adbe-2025-stockholder-letter.pdf', 'page': 3, 'type': 'text'}, page_content='governments around the world establish a federal anti-\\nimpersonation right enabling creators to take action against \\nthose who intentionally misuse AI tools to impersonate their \\nstyle.\\u202fWe continue to work toward reducing our impact on'), Document(id='f88bc9e3-7eaa-4007-ba66-0d3328063393', metadata={'source': 'adbe-2024-annual-report.pdf', 'page': 65, 'type': 'text'}, page_content='conferencing, document and forms platform, web app development, high-end printing and our Adobe Advertising \\nofferings.\\nADOBE INC.\\n NOTES TO CONSOLIDATED FINANCIAL STATEMENTS (Continued)\\n65'), Document(id='8d74f577-7550-479e-ab73-e7f38bcdfeb4', metadata={'source': 'adbe-2025-proxy-statemnt.pdf', 'page': 3, 'type': 'text'}, page_content='to quickly plan, create, manage, activate and measure on-\\nbrand content is resonating with customers and validating \\nour leadership across data, content and journeys to deliver \\npersonalized experiences at scale. We also released')] ---\n",
      "\n",
      "--- Reranked CONTEXT DOC: [] ---\n",
      "\n",
      "--- Reflection: Reflection: YES.  \n",
      "Reflection score: 9.  \n",
      "Explanation: The answer provides a clear and concise explanation of how Adobe is integrating generative AI into its Creative Cloud suite. It mentions specific features such as AI-driven content creation, automated design suggestions, and enhanced editing tools, which are relevant to the question. The answer effectively communicates the purpose of these integrations, which is to enhance creativity and productivity, streamline workflows, and expand creative possibilities for users. However, the answer could be improved by providing specific examples of applications or tools within the Creative Cloud suite that are utilizing these AI capabilities, which would make the response even more comprehensive. ---\n"
     ]
    }
   ],
   "source": [
    "initial_state = RAGReflectionState(\n",
    "        question=question4\n",
    "    )\n",
    "final_state = adobe_rag_app_with_reranker.invoke(initial_state)\n",
    "\n",
    "print(\"QUESTION--  \",initial_state.question)\n",
    "\n",
    "print(f\"--- FINAL ANSWER ---\\n\\n{final_state['answer']}\\n\")\n",
    "print(f\"--- ATTEMPTS: {final_state['attempts']} ---\\n\")\n",
    "print(f\"--- CONTEXT DOC: {final_state['retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reranked CONTEXT DOC: {final_state['rerank_retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reflection: {final_state['reflection']} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION--   Based on the R&D spend and product roadmap, which product is Adobe prioritizing for 2025?.\n",
      "--- FINAL ANSWER ---\n",
      "\n",
      "I'm sorry, but there is no specific context provided regarding Adobe's R&D spend and product roadmap for 2025. Please provide the necessary details or context to assist you better.\n",
      "\n",
      "--- ATTEMPTS: 1 ---\n",
      "\n",
      "--- CONTEXT DOC: [Document(id='60579121-f7f2-4bb2-b879-165ab36a8c2c', metadata={'source': 'adbe-Q4 and FY24 Earnings.pdf', 'page': 2, 'type': 'text'}, page_content='The following table summarizes Adobe’s fiscal year 2025 targets1: \\n \\nTotal revenue \\n$23.30 billion to $23.55 billion \\nDigital Media segment revenue \\n$17.25 billion to $17.40 billion \\nDigital Media ending ARR growth \\n11.0% year over year \\nDigital Experience segment revenue \\n$5.80 billion to $5.90 billion \\nDigital Experience subscription revenue \\n$5.375 billion to $5.425 billion \\nEarnings per share \\nGAAP: $15.80 to $16.10 \\nNon-GAAP: $20.20 to $20.50 \\n1 Targets assume non-GAAP operating margin of ~46 percent, non-GAAP tax rate of ~18.5 percent and diluted share count of ~433 \\nmillion for fiscal year 2025. \\nThe following table summarizes Adobe’s first quarter fiscal year 2025 targets2: \\n \\nTotal revenue \\n$5.63 billion to $5.68 billion \\nDigital Media segment revenue'), Document(id='fd93a746-ca44-4e8b-8af2-4fb13771aa98', metadata={'source': 'Adobe Reports Record Q4 and FY2025 Revenue.pdf', 'page': 2, 'type': 'text'}, page_content='The following table summarizes Adobe’s first quarter FY2026 targets2:\\nTotal revenue\\n$6.25 billion to $6.30 billion\\nBusiness Professionals & Consumers subscription revenue\\n$1.74 billion to $1.76 billion\\nCreative & Marketing Professionals subscription revenue\\n$4.30 billion to $4.33 billion\\nEarnings per share\\nGAAP: $4.55 to $4.60\\nNon-GAAP: $5.85 to $5.90\\n2 Targets assume non-GAAP operating margin of ~47.0%, GAAP tax rate of ~21.5%, non-GAAP tax rate of ~18.0% and diluted \\nshare count of ~411 million for first quarter FY2026.\\n2'), Document(id='aaa499d6-8a69-48b2-b128-81b5e4850074', metadata={'source': 'adbe-2025-proxy-statemnt.pdf', 'page': 59, 'type': 'text'}, page_content='appropriate expenses for the benefit of Adobe and its stockholders. Since the costs arise from the nature of our CEO’s role and \\nExecutive Compensation  |  2025 Proxy Statement       49'), Document(id='0d551acb-53c7-4a1e-8c9f-6f4220bbae86', metadata={'source': 'adbe-Q4 and FY24 Earnings.pdf', 'page': 2, 'type': 'text'}, page_content='website: http://www.adobe.com/ADBE. Earnings documents, including Adobe management’s prepared conference call remarks with slides \\nand an investor datasheet are posted to Adobe’s Investor Relations Website in advance of the conference call for reference.'), Document(id='b725393b-0de6-4f00-ac2a-563724948f5a', metadata={'source': 'adbe-2024-annual-report.pdf', 'page': 55, 'type': 'text'}, page_content='ADOBE INC.\\nCONSOLIDATED STATEMENTS OF INCOME\\n(In millions, except per share data)\\n \\nYears Ended\\n \\nNovember 29,\\n2024\\nDecember 1,\\n2023\\nDecember 2,\\n2022\\nRevenue:\\n \\nSubscription     ...................................................................................................... $ \\n20,521 $ \\n18,284 $ \\n16,388 \\nProduct    .............................................................................................................  \\n386  \\n460  \\n532 \\nServices and other      ............................................................................................  \\n598  \\n665  \\n686 \\nTotal revenue     ...............................................................................................  \\n21,505  \\n19,409  \\n17,606 \\n \\nCost of revenue:')] ---\n",
      "\n",
      "--- Reranked CONTEXT DOC: [] ---\n",
      "\n",
      "--- Reflection: Reflection: YES  \n",
      "Reflection score: 9  \n",
      "Explanation: The answer is appropriate given the lack of context provided. Without specific information about Adobe's R&D spend and product roadmap for 2025, it is impossible to determine which product Adobe is prioritizing. The response correctly identifies the absence of necessary details and requests additional information, which is a suitable approach in this situation. The only reason it is not a perfect 10 is that it could have included a suggestion to check Adobe's official announcements or reports for such information. ---\n"
     ]
    }
   ],
   "source": [
    "initial_state = RAGReflectionState(\n",
    "        question=question5\n",
    "    )\n",
    "final_state = adobe_rag_app_with_reranker.invoke(initial_state)\n",
    "\n",
    "print(\"QUESTION--  \",initial_state.question)\n",
    "\n",
    "print(f\"--- FINAL ANSWER ---\\n\\n{final_state['answer']}\\n\")\n",
    "print(f\"--- ATTEMPTS: {final_state['attempts']} ---\\n\")\n",
    "print(f\"--- CONTEXT DOC: {final_state['retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reranked CONTEXT DOC: {final_state['rerank_retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reflection: {final_state['reflection']} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION--   Who is the current CEO of Adobe's main competitor, Canva?\n",
      "--- FINAL ANSWER ---\n",
      "\n",
      "I am an Adobe-specific assistant. I can only answer questions related to Adobe's reports and products.\n",
      "\n",
      "--- ATTEMPTS: 0 ---\n",
      "\n",
      "--- CONTEXT DOC: [] ---\n",
      "\n",
      "--- Reranked CONTEXT DOC: [] ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initial_state = RAGReflectionState(\n",
    "        question=\"Who is the current CEO of Adobe's main competitor, Canva?\"\n",
    "    )\n",
    "final_state = adobe_rag_app_with_reranker.invoke(initial_state)\n",
    "\n",
    "print(\"QUESTION--  \",initial_state.question)\n",
    "\n",
    "print(f\"--- FINAL ANSWER ---\\n\\n{final_state['answer']}\\n\")\n",
    "print(f\"--- ATTEMPTS: {final_state['attempts']} ---\\n\")\n",
    "print(f\"--- CONTEXT DOC: {final_state['retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reranked CONTEXT DOC: {final_state['rerank_retrieved_docs']} ---\\n\")\n",
    "# print(f\"--- Reflection: {final_state['reflection']} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION--   Which departments of adobe are underperforming in 2024 as per annual report?\n",
      "--- FINAL ANSWER ---\n",
      "\n",
      "I'm sorry, but I don't have access to the 2024 annual report or any specific data regarding the performance of Adobe's departments in 2024. My training only includes data up to October 2023. For the most accurate and up-to-date information, I recommend checking Adobe's official financial reports or press releases.\n",
      "\n",
      "--- ATTEMPTS: 1 ---\n",
      "\n",
      "--- CONTEXT DOC: [Document(id='8e6ec87c-55d6-4724-9d9f-45b3bbbe646c', metadata={'source': 'adbe-2025-proxy-statemnt.pdf', 'page': 64, 'type': 'text'}, page_content='•\\ncompanies that compete with us for talent;\\n•\\npositive revenue growth; and\\n•\\ncompanies that list Adobe as a peer.\\nBased on the factors described above, acquisition of prior peers and input from management and Compensia, the \\nCommittee approved the below peer group for fiscal year 2024. \\n54'), Document(id='aaa499d6-8a69-48b2-b128-81b5e4850074', metadata={'source': 'adbe-2025-proxy-statemnt.pdf', 'page': 59, 'type': 'text'}, page_content='appropriate expenses for the benefit of Adobe and its stockholders. Since the costs arise from the nature of our CEO’s role and \\nExecutive Compensation  |  2025 Proxy Statement       49'), Document(id='f88bc9e3-7eaa-4007-ba66-0d3328063393', metadata={'source': 'adbe-2024-annual-report.pdf', 'page': 65, 'type': 'text'}, page_content='conferencing, document and forms platform, web app development, high-end printing and our Adobe Advertising \\nofferings.\\nADOBE INC.\\n NOTES TO CONSOLIDATED FINANCIAL STATEMENTS (Continued)\\n65'), Document(id='b725393b-0de6-4f00-ac2a-563724948f5a', metadata={'source': 'adbe-2024-annual-report.pdf', 'page': 55, 'type': 'text'}, page_content='ADOBE INC.\\nCONSOLIDATED STATEMENTS OF INCOME\\n(In millions, except per share data)\\n \\nYears Ended\\n \\nNovember 29,\\n2024\\nDecember 1,\\n2023\\nDecember 2,\\n2022\\nRevenue:\\n \\nSubscription     ...................................................................................................... $ \\n20,521 $ \\n18,284 $ \\n16,388 \\nProduct    .............................................................................................................  \\n386  \\n460  \\n532 \\nServices and other      ............................................................................................  \\n598  \\n665  \\n686 \\nTotal revenue     ...............................................................................................  \\n21,505  \\n19,409  \\n17,606 \\n \\nCost of revenue:'), Document(id='14a41af7-88d5-427c-90a9-7ce7815a0e25', metadata={'source': 'adbe-2025-proxy-statemnt.pdf', 'page': 99, 'type': 'text'}, page_content='into any filing of Adobe under the Securities Act, or the Exchange Act whether made before or after the date hereof and irrespective \\nof any general incorporation language in any such filing.\\nManagement Proposals  |  2025 Proxy Statement       89')] ---\n",
      "\n",
      "--- Reranked CONTEXT DOC: [] ---\n",
      "\n",
      "--- Reflection: Reflection: YES  \n",
      "Reflection score: 9  \n",
      "Explanation: The answer is satisfactory because it clearly explains the limitations of the AI's knowledge, which is up to October 2023, and provides a reasonable suggestion for obtaining the most accurate and up-to-date information by checking Adobe's official financial reports or press releases. The response is clear, concise, and appropriately addresses the question given the context. The only reason it is not a perfect 10 is that it could have included a brief explanation of why the AI does not have access to future data, such as the nature of its training data. ---\n"
     ]
    }
   ],
   "source": [
    "initial_state = RAGReflectionState(\n",
    "        question=\"Which departments of adobe are underperforming in 2024 as per annual report?\"\n",
    "    )\n",
    "final_state = adobe_rag_app_with_reranker.invoke(initial_state)\n",
    "\n",
    "print(\"QUESTION--  \",initial_state.question)\n",
    "\n",
    "print(f\"--- FINAL ANSWER ---\\n\\n{final_state['answer']}\\n\")\n",
    "print(f\"--- ATTEMPTS: {final_state['attempts']} ---\\n\")\n",
    "print(f\"--- CONTEXT DOC: {final_state['retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reranked CONTEXT DOC: {final_state['rerank_retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reflection: {final_state['reflection']} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What was Adobe's exact electricity bill for its San Jose headquarters in 2024?\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### List of questions -\n",
    "\n",
    "# Financial Performance (Numerical Accuracy)\n",
    "\"What was Adobe's total revenue for Fiscal Year 2024?\",\n",
    "\"How does the Q4 2024 revenue compare to Q4 2023?\",\n",
    "\"What were the GAAP vs. Non-GAAP operating margins reported in the update?\",\n",
    "\"Which business segment—Digital Media or Digital Experience—showed higher year-over-year growth?\",\n",
    "\"What is Adobe's revenue guidance for the full year 2025?\",\n",
    "\n",
    "# AI & Strategy (Semantic Understanding)\n",
    "\"How is Adobe integrating generative AI across its Creative Cloud suite?\",\n",
    "\"What are the primary use cases mentioned for Adobe Firefly in the enterprise sector?\",\n",
    "\"What does the report cite as Adobe's primary competitive advantage in the AI era?\",\n",
    "\"How is Adobe planning to monetize its new AI-driven features (e.g., 'Generative Credits')?\",\n",
    "\"Mention any key strategic partnerships highlighted in the 2024 update.\",\n",
    "\n",
    "# Multimodal / Image-Based (Testing CLIP & Vision)\n",
    "\"Based on the 'Digital Media ARR' chart, what was the ending ARR for 2024?\",\n",
    "\"Look at the slide showing the 'Content Supply Chain.' What are the four main stages of the workflow?\",\n",
    "\"According to the Acrobat AI Assistant slide, what percentage increase in productivity was noted?\",\n",
    "\"Which external partner logos appear on the 'Ecosystem' slide?\",\n",
    "\n",
    "# Complex Reasoning (Multi-Step Retrieval)\n",
    "\"Summarize the three biggest risks Adobe identifies regarding the adoption of AI.\",\n",
    "\"Based on the R&D spend and product roadmap, which product is Adobe prioritizing for 2025?\",\n",
    "\"The report mentions 'Record Revenue,' but are there any segments that saw a decline? If so, which ones?\",\n",
    "\"What is the percentage change in Adobe's stock repurchase program compared to the previous year?\",\n",
    "\n",
    "\n",
    "# Guardrails & Robustness (Agent Reflection)\n",
    "\"Who is the current CEO of Adobe's main competitor, Canva?\",\n",
    "\"What was Adobe's exact electricity bill for its San Jose headquarters in 2024?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assuming the available Adobe document do not contain any scanned images - below approach is taken with better embedding model and retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Load pretrained SentenceTransformer: BAAI/bge-large-en-v1.5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Check for Mac GPU (MPS)\n",
    "device = \"cpu\"\n",
    "\n",
    "# Initialize BGE-Large\n",
    "# BGE v1.5 requires a specific query instruction for better retrieval\n",
    "model_name = TEXT_EMBEDDING\n",
    "model_kwargs = {'device': device}\n",
    "encode_kwargs = {'normalize_embeddings': True} # Essential for BGE v1.5\n",
    "\n",
    "bge_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [00:10<00:01,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9031 documents from the folder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "# This scans the folder and uses Unstructured for each file found\n",
    "loader = DirectoryLoader(\n",
    "    DATA_FOLDER, \n",
    "    glob=\"**/*.*\", # Adjust pattern to filter files (e.g., \"**/*.pdf\")\n",
    "    loader_cls=UnstructuredLoader,\n",
    "    show_progress=True,\n",
    "    use_multithreading=True,\n",
    "    loader_kwargs={\"languages\": [\"eng\"], \"strategy\": \"fast\"}\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} documents from the folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9031"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 9073\n"
     ]
    }
   ],
   "source": [
    "### Using different embedding strategy\n",
    "\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "# 2. Apply Recursive Chunking\n",
    "# 1000 characters is ~250 tokens, well within BGE's 512-token limit\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=150,\n",
    "    add_start_index=True,\n",
    "    strip_whitespace=True\n",
    ")\n",
    "\n",
    "all_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3. Add Metadata for your RAG Agent\n",
    "for i, chunk in enumerate(all_chunks):\n",
    "    chunk.metadata[\"type\"] = \"text\"\n",
    "    chunk.metadata[\"chunk_id\"] = i\n",
    "\n",
    "print(f\"Total chunks created: {len(all_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Loading faiss.\n",
      "INFO: Successfully loaded faiss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGE Vector Store created and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create the vector store\n",
    "# This will take a moment as it processes 1800+ chunks on your Mac\n",
    "text_vectorstore = FAISS.from_documents(\n",
    "    documents=all_chunks,\n",
    "    embedding=bge_embeddings\n",
    ")\n",
    "\n",
    "# Save the index locally so you don't have to re-embed next time\n",
    "text_vectorstore.save_local(\"./vectore_store_db/faiss_bge_index\")\n",
    "\n",
    "print(\"BGE Vector Store created and saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class RAGReflectionState(BaseModel):\n",
    "    # Required field\n",
    "    question: str\n",
    "    \n",
    "    # Fields with explicit defaults (making them truly optional for .invoke)\n",
    "    retrieved_docs: List[Document] = Field(default_factory=list) \n",
    "    rerank_retrieved_docs: List[Document] = Field(default_factory=list)\n",
    "    answer: Optional[str] = None\n",
    "    reflection: Optional[str] = None\n",
    "    revised: bool = False\n",
    "    attempts: int = 0\n",
    "    is_allowed: bool = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "import json\n",
    "\n",
    "\n",
    "# --- NODE 1: RETRIEVER ---\n",
    "def retriever_node(state: RAGReflectionState) -> RAGReflectionState:\n",
    "    query = state.question \n",
    "    # Using your unified CLIP retrieval function\n",
    "    docs = text_vectorstore.similarity_search(query, k=8)\n",
    "    return {\"retrieved_docs\": docs}\n",
    "\n",
    "\n",
    "## NODE 2 : ReRANKER\n",
    "def rerank_documents_node(state: RAGReflectionState):\n",
    "    query = state.question\n",
    "    docs = state.retrieved_docs\n",
    "    \n",
    "    if not docs:\n",
    "        return {\"retrieved_docs\": [], \"rerank_retrieved_docs\": []}\n",
    "\n",
    "    # Format documents for the LLM\n",
    "    doc_texts = \"\\n\".join([\n",
    "        f\"ID: {i}\\nContent: {doc.page_content[:500]}\" \n",
    "        for i, doc in enumerate(docs)\n",
    "    ])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert search ranker. Given the user query and a list of documents, \n",
    "    determine which documents are most relevant to answer the question.\n",
    "    \n",
    "    Query: {query}\n",
    "    \n",
    "    Documents:\n",
    "    {doc_texts}\n",
    "    \n",
    "    Return only a JSON list of IDs in order of relevance, for example: [2, 0, 3].\n",
    "    Only include IDs of documents that are truly relevant.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get ranking from LLM\n",
    "    response = llm.invoke(prompt)\n",
    "    try:\n",
    "        # Extract ID list from response\n",
    "        # Using a simple strip in case LLM adds markdown backticks\n",
    "        raw_content = response.content.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        relevant_ids = json.loads(raw_content)\n",
    "        \n",
    "        # Reorder and filter original docs based on LLM decision\n",
    "        rerank_retrieved_docs = [docs[idx] for idx in relevant_ids if idx < len(docs)]\n",
    "    except Exception as e:\n",
    "        print(f\"Reranking failed, falling back to original docs: {e}\")\n",
    "        rerank_retrieved_docs = docs[:3] # Fallback to top 3\n",
    "\n",
    "    return {\"rerank_retrieved_docs\": rerank_retrieved_docs}\n",
    "\n",
    "\n",
    "\n",
    "# --- NODE 3: ANSWER GENERATOR ---\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "def generate_answer_node(state: RAGReflectionState):\n",
    "    # 1. Format the retrieved docs into a readable string for the LLM\n",
    "    # Passing raw Document objects inside an f-string can be messy\n",
    "    context_str = \"\\n\\n\".join([\n",
    "        f\"[Source: {d.metadata.get('source', 'Unknown')}, Page: {d.metadata.get('page_number', 'N/A')}]\\n{d.page_content}\"\n",
    "        for d in state.rerank_retrieved_docs\n",
    "    ])\n",
    "    \n",
    "    system_message = \"\"\"\n",
    "            You are the \"Adobe AI Leadership Insight & Decision Agent,\" a specialized financial analyst.\n",
    "            Your goal is to provide high-fidelity answers based on Adobe's internal reports, charts, and data.\n",
    "\n",
    "            STRICT GUIDELINES:\n",
    "            1. ONLY use the provided context to answer.\n",
    "            2. If the answer is not in the context, state: \"I'm sorry, I cannot find that information in the current Adobe reports.\"\n",
    "            3. When referencing a chart or image, specify the Page Number.\n",
    "            4. If there is a conflict between an image (chart) and text, prioritize the data found in the image.\n",
    "            5. Be concise, professional, and use bullet points for financial data.\n",
    "            \"\"\"\n",
    "\n",
    "    # 2. Use placeholders {} in the template instead of f-strings\n",
    "    # This allows the Template object to handle the insertion correctly\n",
    "    human_template = f\"\"\"\n",
    "            ### CONTEXT DATA:\n",
    "            {context_str}\n",
    "\n",
    "            ### USER QUESTION:\n",
    "            {state.question}\n",
    "\n",
    "            ### YOUR ANALYSIS:\n",
    "            \"\"\"\n",
    "\n",
    "    # 3. Create the Template\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_message),\n",
    "        (\"human\", human_template)\n",
    "    ])\n",
    "\n",
    "    # 4. FIX: Format the template with actual data to get a list of messages\n",
    "    messages = prompt_template.format_messages(\n",
    "        context=context_str,\n",
    "        question=state.question\n",
    "    )\n",
    "\n",
    "    # 5. Pass the formatted messages to the LLM\n",
    "    response = llm.invoke(messages)\n",
    "        \n",
    "    return {\n",
    "        \"answer\": response.content.strip(),\n",
    "        \"attempts\": state.attempts + 1\n",
    "    }\n",
    "\n",
    "\n",
    "# --- NODE 4: REFLECTOR ---\n",
    "def reflection_node(state: RAGReflectionState)  -> RAGReflectionState:\n",
    "    prompt = f\"\"\"\n",
    "    Reflect on the following answer and context. State \"YES\" if satisfactory or \"NO\" if not.\n",
    "    Question: {state.question}\n",
    "    Answer: {state.answer}\n",
    "    Context: {state.rerank_retrieved_docs}\n",
    "    Respond like:\n",
    "    Reflection: YES or NO. \n",
    "    Reflection score: 0-10 (10 being perfect)\n",
    "    Explanation: ...\n",
    "    \"\"\"\n",
    "    \n",
    "    reflection = llm.invoke(prompt).content\n",
    "    is_ok = \"reflection: yes\" in reflection.lower()\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        \"reflection\": reflection, \n",
    "        \"revised\": not is_ok\n",
    "    }\n",
    "\n",
    "# --- NODE 5: FINALIZER ---\n",
    "# def finalize_node(state: RAGReflectionState)    -> RAGReflectionState:\n",
    "#     # This node just acts as a cleanup/formatting step before END\n",
    "#     return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In your finalize_node, handle the blocked message\n",
    "def finalize_node(state: RAGReflectionState):\n",
    "    if not state.is_allowed:\n",
    "        return {\"answer\": \"I am an Adobe-specific assistant. I can only answer questions related to Adobe's reports and products.\"}\n",
    "    # ... (rest of your finalize logic)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardrail_node(state: RAGReflectionState):\n",
    "    prompt = f\"\"\"\n",
    "    You are a security gatekeeper for an Adobe Financial RAG agent. \n",
    "    Your task is to determine if the following question is related to Adobe (its finances, products like Photoshop/Firefly, strategy, or reports).\n",
    "\n",
    "    Question: {state.question}\n",
    "\n",
    "    If the question is about Adobe, respond exactly with \"ALLOWED\".\n",
    "    If it is NOT about Adobe (e.g., asking about cooking, other companies like Apple, or general trivia), respond with \"BLOCKED\".\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt).content.strip().upper()\n",
    "    is_allowed = \"ALLOWED\" in response\n",
    "    \n",
    "    return {\"is_allowed\": is_allowed}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building graph workflow \n",
    "\n",
    "\n",
    "# Conditional Logic: Loop back to retriever if \"revised\" is True and attempts < 2\n",
    "def route_after_reflection(state: RAGReflectionState):\n",
    "    if not state.revised or state.attempts >= 2:\n",
    "        return \"complete\"\n",
    "    else:\n",
    "        return \"retry\"\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Rebuild with Reranking Node \n",
    "\n",
    "builder = StateGraph(RAGReflectionState)\n",
    "\n",
    "\n",
    "\n",
    "# Add Nodes\n",
    "builder.add_node(\"guardrail\", guardrail_node)\n",
    "builder.add_node(\"retriever\", retriever_node)\n",
    "builder.add_node(\"reranker\", rerank_documents_node) \n",
    "builder.add_node(\"answer_generator\", generate_answer_node)\n",
    "builder.add_node(\"reflector\", reflection_node)\n",
    "builder.add_node(\"done\", finalize_node)\n",
    "\n",
    "# # Update Flow (Edges)\n",
    "# builder.set_entry_point(\"retriever\")\n",
    "\n",
    "\n",
    "\n",
    "# Define the gatekeeping flow\n",
    "builder.set_entry_point(\"guardrail\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"guardrail\",\n",
    "    lambda s: \"continue\" if s.is_allowed else \"stop\",\n",
    "    {\n",
    "        \"continue\": \"retriever\",\n",
    "        \"stop\": \"done\" # Skip directly to finalize\n",
    "    }\n",
    ")\n",
    "builder.add_edge(\"retriever\", \"reranker\")        \n",
    "builder.add_edge(\"reranker\", \"answer_generator\")\n",
    "builder.add_edge(\"answer_generator\", \"reflector\")\n",
    "\n",
    "# Update Conditional Logic\n",
    "builder.add_conditional_edges(\n",
    "    \"reflector\",\n",
    "    route_after_reflection,\n",
    "    {\n",
    "        \"complete\": \"done\",\n",
    "        \"retry\": \"retriever\" # Retry starts back at retrieval\n",
    "    }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"done\", END)\n",
    "adobe_rag_app_with_reranker = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION--   Based on the R&D spend and product roadmap, which product is Adobe prioritizing for 2025?.\n",
      "--- FINAL ANSWER ---\n",
      "\n",
      "I'm sorry, I cannot find that information in the current Adobe reports.\n",
      "\n",
      "--- ATTEMPTS: 2 ---\n",
      "\n",
      "--- CONTEXT DOC: [Document(id='5ca40677-328a-467b-b152-7dd106c7b487', metadata={'source': 'data/adbe-Q4 and FY24 Earnings.pdf', 'coordinates': {'points': ((49.464, 376.72200000000004), (49.464, 386.48784), (286.39456, 386.48784), (286.39456, 376.72200000000004)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': 'data', 'filename': 'adbe-Q4 and FY24 Earnings.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:51:28', 'page_number': 2, 'filetype': 'application/pdf', 'parent_id': '56a55169e1ca3108bcacf5211693b934', 'category': 'NarrativeText', 'element_id': '4e4d5aa3e89245e25c421ef477b2153b', 'start_index': 0, 'type': 'text', 'chunk_id': 31}, page_content='The following table summarizes Adobe’s fiscal year 2025 targets1:'), Document(id='2214590d-0d01-45e7-97e0-1b4004042002', metadata={'source': 'data/adbe-Q2-FY25-earnings.pdf', 'coordinates': {'points': ((49.5, 275.01964999999996), (49.5, 286.181), (503.603, 286.181), (503.603, 275.01964999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': 'data', 'filename': 'adbe-Q2-FY25-earnings.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:51:46', 'page_number': 2, 'filetype': 'application/pdf', 'parent_id': 'cd3b4b8cce6d328660f5e7579e4017da', 'category': 'NarrativeText', 'element_id': '8a758f919816a82fa79147c3944d0ab9', 'start_index': 0, 'type': 'text', 'chunk_id': 506}, page_content='The following updated table summarizes Adobe’s fiscal year 2025 targets, which assumes current macroeconomic conditions2:'), Document(id='a9f3fb08-4dee-46f8-bd7d-941789fa3bf7', metadata={'source': 'data/adbe-Q3-FY25-earnings.pdf', 'coordinates': {'points': ((49.5, 295.6372), (49.5, 305.431), (503.603, 305.431), (503.603, 295.6372)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': 'data', 'filename': 'adbe-Q3-FY25-earnings.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:51:55', 'page_number': 2, 'filetype': 'application/pdf', 'parent_id': '6c144ac179caa1a73330d837331e787b', 'category': 'NarrativeText', 'element_id': '70a2f23f5e8058d63af664d4e4d6c54e', 'start_index': 0, 'type': 'text', 'chunk_id': 1802}, page_content='The following updated table summarizes Adobe’s fiscal year 2025 targets, which assumes current macroeconomic conditions2:'), Document(id='e34e0e1e-9f6b-4433-bcaa-79bc12ef3a46', metadata={'source': 'data/adbe-Q4 and FY24 Earnings.pdf', 'coordinates': {'points': ((49.464, 524.1020000000001), (49.464, 533.86784), (329.85456, 533.86784), (329.85456, 524.1020000000001)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': 'data', 'filename': 'adbe-Q4 and FY24 Earnings.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:51:28', 'page_number': 2, 'filetype': 'application/pdf', 'parent_id': 'c43947ba49d77bb6bfe4e3cd686d2f7c', 'category': 'NarrativeText', 'element_id': 'e65a2507c0791663c929727fd34a49fe', 'start_index': 0, 'type': 'text', 'chunk_id': 47}, page_content='The following table summarizes Adobe’s first quarter fiscal year 2025 targets2:'), Document(id='153ba8ce-4a5e-4960-8790-942d6d2b1011', metadata={'source': 'data/adbe-Q3-FY25-earnings.pdf', 'coordinates': {'points': ((49.5, 163.22717), (49.5, 173.02099999999996), (523.14298, 173.02099999999996), (523.14298, 163.22717)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': 'data', 'filename': 'adbe-Q3-FY25-earnings.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:51:55', 'page_number': 2, 'filetype': 'application/pdf', 'parent_id': '10ef2ec72cd58825ff3d6a3eb14fd5bd', 'category': 'NarrativeText', 'element_id': 'a822fbcb0fea6c6b22be9314d85f097f', 'start_index': 0, 'type': 'text', 'chunk_id': 1788}, page_content='The following table summarizes Adobe’s fourth quarter fiscal year 2025 targets, which assumes current macroeconomic conditions1:'), Document(id='ea869bac-ddee-440d-a83f-e8e2486acc40', metadata={'source': 'data/adbe-Q2-FY25-earnings.pdf', 'coordinates': {'points': ((49.5, 142.60966999999994), (49.5, 153.77099999999996), (518.13297, 153.77099999999996), (518.13297, 142.60966999999994)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': 'data', 'filename': 'adbe-Q2-FY25-earnings.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:51:46', 'page_number': 2, 'filetype': 'application/pdf', 'parent_id': 'dd91cdc74ba71557a8aed97ea718fe15', 'category': 'NarrativeText', 'element_id': '7c00b8dcb410db8056f1e9b6d38020cc', 'start_index': 0, 'type': 'text', 'chunk_id': 492}, page_content='The following table summarizes Adobe’s third quarter fiscal year 2025 targets, which assumes current macroeconomic conditions1:'), Document(id='52267cb1-6eac-4d4a-ab7c-665047c12961', metadata={'source': 'data/adbe-2024-annual-report.pdf', 'coordinates': {'points': ((49.5, 275.843076), (49.5, 369.843076), (565.0, 369.843076), (565.0, 275.843076)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': 'data', 'filename': 'adbe-2024-annual-report.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:49:15', 'page_number': 18, 'filetype': 'application/pdf', 'parent_id': 'c48f436d79e008b56cfbc10e2987b29e', 'category': 'NarrativeText', 'element_id': '194ba3ca0821898b2c83a5ae738a1e76', 'start_index': 0, 'type': 'text', 'chunk_id': 6398}, page_content='With the speed of innovation and technological change that characterizes the software industry, a continuous high level of investment is required for the research and development of the cutting-edge technologies that lead to the development of new products, services and solutions and the continual enhancement of existing products, services and solutions. Our Adobe Research team of research scientists, engineers, artists and designers help turn ideas into technologies that power the future of our products, services and solutions. We are investing, and intend to continue to invest, in research and development to strengthen our existing products, services and solutions, and to expand our offerings across our clouds and the next generation of AI, machine learning and deep learning-driven tools'), Document(id='85957b8d-cd76-4ba0-a1b0-4a77fbb6ca4a', metadata={'source': 'data/Adobe Reports Record Q4 and FY2025 Revenue.pdf', 'coordinates': {'points': ((49.5, 334.331), (49.5, 365.831), (549.7010010000002, 365.831), (549.7010010000002, 334.331)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': 'data', 'filename': 'Adobe Reports Record Q4 and FY2025 Revenue.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:55:20', 'page_number': 1, 'filetype': 'application/pdf', 'parent_id': '6efee8f9a83e0714f9c1dcf8297a2b5d', 'category': 'NarrativeText', 'element_id': '87c2596bb51b844ac9ee9199a292eb61', 'start_index': 0, 'type': 'text', 'chunk_id': 1070}, page_content='SAN JOSE, Calif. – Dec. 10, 2025 – Adobe (Nasdaq:ADBE), the global technology leader that unleashes creativity and productivity for individuals and businesses through innovative platforms and tools, today reported financial results for its fourth quarter and FY2025 ended Nov. 28, 2025.')] ---\n",
      "\n",
      "--- Reranked CONTEXT DOC: [Document(id='52267cb1-6eac-4d4a-ab7c-665047c12961', metadata={'source': 'data/adbe-2024-annual-report.pdf', 'coordinates': {'points': ((49.5, 275.843076), (49.5, 369.843076), (565.0, 369.843076), (565.0, 275.843076)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': 'data', 'filename': 'adbe-2024-annual-report.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:49:15', 'page_number': 18, 'filetype': 'application/pdf', 'parent_id': 'c48f436d79e008b56cfbc10e2987b29e', 'category': 'NarrativeText', 'element_id': '194ba3ca0821898b2c83a5ae738a1e76', 'start_index': 0, 'type': 'text', 'chunk_id': 6398}, page_content='With the speed of innovation and technological change that characterizes the software industry, a continuous high level of investment is required for the research and development of the cutting-edge technologies that lead to the development of new products, services and solutions and the continual enhancement of existing products, services and solutions. Our Adobe Research team of research scientists, engineers, artists and designers help turn ideas into technologies that power the future of our products, services and solutions. We are investing, and intend to continue to invest, in research and development to strengthen our existing products, services and solutions, and to expand our offerings across our clouds and the next generation of AI, machine learning and deep learning-driven tools')] ---\n",
      "\n",
      "--- Reflection: Reflection: NO.  \n",
      "Reflection score: 3.  \n",
      "Explanation: The answer provided is not satisfactory because it does not directly address the question about which specific product Adobe is prioritizing for 2025 based on R&D spend and the product roadmap. The context provided from the Adobe report discusses the general investment in research and development and mentions areas like AI, machine learning, and deep learning, but it does not specify a particular product being prioritized for 2025. Therefore, the answer should have acknowledged the lack of specific information in the context and possibly suggested looking for more detailed sources or reports that might contain the desired information. ---\n"
     ]
    }
   ],
   "source": [
    "initial_state = RAGReflectionState(\n",
    "        question=question5\n",
    "    )\n",
    "final_state = adobe_rag_app_with_reranker.invoke(initial_state)\n",
    "\n",
    "print(\"QUESTION--  \",initial_state.question)\n",
    "\n",
    "print(f\"--- FINAL ANSWER ---\\n\\n{final_state['answer']}\\n\")\n",
    "print(f\"--- ATTEMPTS: {final_state['attempts']} ---\\n\")\n",
    "print(f\"--- CONTEXT DOC: {final_state['retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reranked CONTEXT DOC: {final_state['rerank_retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reflection: {final_state['reflection']} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION--   Who is the current CEO of Adobe's main competitor, Canva?\n",
      "--- FINAL ANSWER ---\n",
      "\n",
      "I am an Adobe-specific assistant. I can only answer questions related to Adobe's reports and products.\n",
      "\n",
      "--- ATTEMPTS: 0 ---\n",
      "\n",
      "--- CONTEXT DOC: [] ---\n",
      "\n",
      "--- Reranked CONTEXT DOC: [] ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initial_state = RAGReflectionState(\n",
    "        question=\"Who is the current CEO of Adobe's main competitor, Canva?\"\n",
    "    )\n",
    "final_state = adobe_rag_app_with_reranker.invoke(initial_state)\n",
    "\n",
    "print(\"QUESTION--  \",initial_state.question)\n",
    "\n",
    "print(f\"--- FINAL ANSWER ---\\n\\n{final_state['answer']}\\n\")\n",
    "print(f\"--- ATTEMPTS: {final_state['attempts']} ---\\n\")\n",
    "print(f\"--- CONTEXT DOC: {final_state['retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reranked CONTEXT DOC: {final_state['rerank_retrieved_docs']} ---\\n\")\n",
    "# print(f\"--- Reflection: {final_state['reflection']} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION--   Which departments of adobe are underperforming in 2024 as per annual report?\n",
      "--- FINAL ANSWER ---\n",
      "\n",
      "I'm sorry, I cannot find that information in the current Adobe reports.\n",
      "\n",
      "--- ATTEMPTS: 1 ---\n",
      "\n",
      "--- CONTEXT DOC: [Document(id='dad80a45-5917-49f4-a47e-7b18b52bbcd3', metadata={'source': 'data/adbe-Q4 and FY24 Earnings.pdf', 'coordinates': {'points': ((49.464, 274.19056), (49.464, 296.27056), (520.2594399999999, 296.27056), (520.2594399999999, 274.19056)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': 'data', 'filename': 'adbe-Q4 and FY24 Earnings.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:51:28', 'page_number': 1, 'filetype': 'application/pdf', 'category': 'Title', 'element_id': '6ceb55a46a99a9636163f3c0135d237e', 'start_index': 0, 'type': 'text', 'chunk_id': 4}, page_content='Adobe Reports Record Q4 and Fiscal 2024 Revenue'), Document(id='b9db6a64-0076-4ab4-9e08-b7418822a694', metadata={'source': 'data/adbe-2025-proxy-statemnt.pdf', 'coordinates': {'points': ((52.41189956600001, 92.609951852), (52.41189956600001, 102.31595185200001), (315.269791566, 102.31595185200001), (315.269791566, 92.609951852)), 'system': 'PixelSpace', 'layout_width': 594.0, 'layout_height': 774.0}, 'file_directory': 'data', 'filename': 'adbe-2025-proxy-statemnt.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:48:04', 'page_number': 41, 'filetype': 'application/pdf', 'category': 'Title', 'element_id': '3a56571681e4ae2319cdf50bef041137', 'start_index': 0, 'type': 'text', 'chunk_id': 3355}, page_content='during fiscal year 2024 for the following executive officers of Adobe:'), Document(id='2798e5d6-28b4-4be6-b7b9-66cdfc48032b', metadata={'source': 'data/adbe-Q4 and FY24 Earnings.pdf', 'coordinates': {'points': ((49.464, 508.18784), (49.464, 528.5878399999999), (535.5055895439999, 528.5878399999999), (535.5055895439999, 508.18784)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': 'data', 'filename': 'adbe-Q4 and FY24 Earnings.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:51:28', 'page_number': 1, 'filetype': 'application/pdf', 'parent_id': 'faebae2d3cedde332e4f1834835f55e5', 'category': 'ListItem', 'element_id': 'c587bdc6f087b3ed33e86cdf7378f4c4', 'start_index': 0, 'type': 'text', 'chunk_id': 10}, page_content='Adobe achieved revenue of $5.61 billion in its fourth quarter of fiscal year 2024, which represents 11 percent year-over-year growth as reported and in constant currency. Diluted earnings per share was $3.79 on a GAAP basis and $4.81 on a non-GAAP basis.'), Document(id='c3cf3763-8bd2-4215-81e4-3d29c181d15c', metadata={'source': 'data/adbe-Q4 and FY24 Earnings.pdf', 'coordinates': {'points': ((49.464, 375.20784), (49.464, 395.60784), (556.0345599999999, 395.60784), (556.0345599999999, 375.20784)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': 'data', 'filename': 'adbe-Q4 and FY24 Earnings.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:51:28', 'page_number': 1, 'filetype': 'application/pdf', 'parent_id': '6ceb55a46a99a9636163f3c0135d237e', 'category': 'NarrativeText', 'element_id': 'b8ea4bf43d81ae00a2721daac2dcdfb8', 'start_index': 0, 'type': 'text', 'chunk_id': 6}, page_content='New Delhi, India. – Dec. 12, 2024 – Adobe (Nasdaq:ADBE) today reported financial results for its fourth quarter and fiscal year 2024 ended Nov. 29, 2024.'), Document(id='526d4893-88d0-4e89-b3ba-67145784ee2d', metadata={'source': 'data/adbe-Q4 and FY24 Earnings.pdf', 'coordinates': {'points': ((49.464, 63.58784000000003), (49.464, 83.98784), (556.3653261759999, 83.98784), (556.3653261759999, 63.58784000000003)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': 'data', 'filename': 'adbe-Q4 and FY24 Earnings.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:51:28', 'page_number': 2, 'filetype': 'application/pdf', 'parent_id': 'd5a3cdfa2c65eadf9ddfbe4d4e4a0ecc', 'category': 'ListItem', 'element_id': 'b7885c4989d7b15fdbc594eb10ff0847', 'start_index': 0, 'type': 'text', 'chunk_id': 20}, page_content='Adobe achieved revenue of $21.51 billion in fiscal year 2024, which represents 11 percent year-over-year growth as reported and in constant currency. Diluted earnings per share was $12.36 on a GAAP basis and $18.42 on a non-GAAP basis.'), Document(id='85957b8d-cd76-4ba0-a1b0-4a77fbb6ca4a', metadata={'source': 'data/Adobe Reports Record Q4 and FY2025 Revenue.pdf', 'coordinates': {'points': ((49.5, 334.331), (49.5, 365.831), (549.7010010000002, 365.831), (549.7010010000002, 334.331)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': 'data', 'filename': 'Adobe Reports Record Q4 and FY2025 Revenue.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:55:20', 'page_number': 1, 'filetype': 'application/pdf', 'parent_id': '6efee8f9a83e0714f9c1dcf8297a2b5d', 'category': 'NarrativeText', 'element_id': '87c2596bb51b844ac9ee9199a292eb61', 'start_index': 0, 'type': 'text', 'chunk_id': 1070}, page_content='SAN JOSE, Calif. – Dec. 10, 2025 – Adobe (Nasdaq:ADBE), the global technology leader that unleashes creativity and productivity for individuals and businesses through innovative platforms and tools, today reported financial results for its fourth quarter and FY2025 ended Nov. 28, 2025.'), Document(id='153ba8ce-4a5e-4960-8790-942d6d2b1011', metadata={'source': 'data/adbe-Q3-FY25-earnings.pdf', 'coordinates': {'points': ((49.5, 163.22717), (49.5, 173.02099999999996), (523.14298, 173.02099999999996), (523.14298, 163.22717)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': 'data', 'filename': 'adbe-Q3-FY25-earnings.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:51:55', 'page_number': 2, 'filetype': 'application/pdf', 'parent_id': '10ef2ec72cd58825ff3d6a3eb14fd5bd', 'category': 'NarrativeText', 'element_id': 'a822fbcb0fea6c6b22be9314d85f097f', 'start_index': 0, 'type': 'text', 'chunk_id': 1788}, page_content='The following table summarizes Adobe’s fourth quarter fiscal year 2025 targets, which assumes current macroeconomic conditions1:'), Document(id='2214590d-0d01-45e7-97e0-1b4004042002', metadata={'source': 'data/adbe-Q2-FY25-earnings.pdf', 'coordinates': {'points': ((49.5, 275.01964999999996), (49.5, 286.181), (503.603, 286.181), (503.603, 275.01964999999996)), 'system': 'PixelSpace', 'layout_width': 612.0, 'layout_height': 792.0}, 'file_directory': 'data', 'filename': 'adbe-Q2-FY25-earnings.pdf', 'languages': ['eng'], 'last_modified': '2026-02-20T11:51:46', 'page_number': 2, 'filetype': 'application/pdf', 'parent_id': 'cd3b4b8cce6d328660f5e7579e4017da', 'category': 'NarrativeText', 'element_id': '8a758f919816a82fa79147c3944d0ab9', 'start_index': 0, 'type': 'text', 'chunk_id': 506}, page_content='The following updated table summarizes Adobe’s fiscal year 2025 targets, which assumes current macroeconomic conditions2:')] ---\n",
      "\n",
      "--- Reranked CONTEXT DOC: [] ---\n",
      "\n",
      "--- Reflection: Reflection: YES.  \n",
      "Reflection score: 9.  \n",
      "Explanation: The answer is satisfactory given the context provided. The context is empty, indicating that there is no specific information available about Adobe's departmental performance in 2024. The response appropriately acknowledges the lack of information in the current reports, which aligns with the context. The only reason it is not a perfect 10 is that it could have included a suggestion to check Adobe's official reports or news releases for the most up-to-date information. ---\n"
     ]
    }
   ],
   "source": [
    "initial_state = RAGReflectionState(\n",
    "        question=\"Which departments of adobe are underperforming in 2024 as per annual report?\"\n",
    "    )\n",
    "final_state = adobe_rag_app_with_reranker.invoke(initial_state)\n",
    "\n",
    "print(\"QUESTION--  \",initial_state.question)\n",
    "\n",
    "print(f\"--- FINAL ANSWER ---\\n\\n{final_state['answer']}\\n\")\n",
    "print(f\"--- ATTEMPTS: {final_state['attempts']} ---\\n\")\n",
    "print(f\"--- CONTEXT DOC: {final_state['retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reranked CONTEXT DOC: {final_state['rerank_retrieved_docs']} ---\\n\")\n",
    "print(f\"--- Reflection: {final_state['reflection']} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adobe-assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
